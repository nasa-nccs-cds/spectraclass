{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from spectraclass.data.base import DataManager\n",
    "from spectraclass.data.base import ModeDataManager\n",
    "from spectraclass.data.spatial.tile.manager import TileManager\n",
    "from spectraclass.data.spatial.modes import AvirisDataManager\n",
    "from spectraclass.application.controller import app, SpectraclassController\n",
    "from spectraclass.model.labels import LabelsManager, lm\n",
    "from spectraclass.learn.manager import ClassificationManager, cm\n",
    "from spectraclass.learn.base import LearningModel\n",
    "import os\n",
    "from typing import List, Union, Tuple, Optional, Dict, Callable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here we configure paths on the Jupyter server.  If these paths are not specified here then the default values,\n",
    "    defined in server-side config files, for the project (\"demo2\") and data mode (\"desis\"), will be used.  You can\n",
    "    choose whatever project names you want, they are used to save configurations and results for ongoing investigations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening log file:  '/Users/tpmaxwel/.spectraclass/logging/aviris/img_mgr.log'\n",
      "Using config file: '/Users/tpmaxwel/Development/Projects/spectraclass/defaults/config.py'\n",
      "Using config file: '/Users/tpmaxwel/.spectraclass/config/aviris/img_mgr.py'\n"
     ]
    }
   ],
   "source": [
    "dm: DataManager = DataManager.initialize( \"img_mgr\", 'aviris' )\n",
    "location = \"desktop\"\n",
    "if location == \"adapt\":\n",
    "    dm.modal.cache_dir = \"/adapt/nobackup/projects/ilab/cache\"\n",
    "    dm.modal.data_dir = \"/css/above/daac.ornl.gov/daacdata/above/ABoVE_Airborne_AVIRIS_NG/data/\"\n",
    "elif location == \"desktop\":\n",
    "    dm.modal.cache_dir = \"/Volumes/Shared/Cache\"\n",
    "    dm.modal.data_dir = \"/Users/tpmaxwel/Development/Data/Aviris\"\n",
    "else: raise Exception( f\"Unknown location: {location}\")\n",
    "    \n",
    "block_size = 200\n",
    "method = \"aec\" # \"vae\"\n",
    "model_dims = 32\n",
    "version = \"v2p9\"  # \"v2v2\" \"v2p9\"\n",
    "preprocess = False\n",
    "\n",
    "dm.use_model_data = True\n",
    "dm.proc_type = \"cpu\"\n",
    "dm.modal.images_glob = f\"ang*rfl/ang*_rfl_{version}/ang*_corr_{version}_img\"\n",
    "TileManager.block_size = block_size\n",
    "TileManager.block_index = [1,5]\n",
    "AvirisDataManager.version = version\n",
    "dm.modal.valid_aviris_bands = [ [5,193], [214,283], [319,10000] ]\n",
    "dm.modal.model_dims = model_dims\n",
    "dm.modal.reduce_method = method\n",
    "dm.modal.reduce_nepoch = 3\n",
    "dm.modal.reduce_focus_nepoch = 10\n",
    "dm.modal.reduce_niter = 1\n",
    "dm.modal.reduce_focus_ratio = 10.0\n",
    "dm.modal.reduce_dropout = 0.0\n",
    "dm.modal.reduce_learning_rate = 1e-4\n",
    "dm.modal.refresh_model = False\n",
    "dm.modal.modelkey = f\"b{block_size}.{method}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here we load the project data and define a set of class names (with associated colors) to be used in the classification process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Reading raster file /Users/tpmaxwel/Development/Data/Aviris/ang20190802t211646rfl/ang20190802t211646_rfl_v2p9/ang20190802t211646_corr_v2p9_img, dims = ('band', 'y', 'x'), shape = (425, 17869, 709)\n",
      "#Tile[0]-> Read Data: shape = (425, 17869, 709), dims=('band', 'y', 'x')\n"
     ]
    }
   ],
   "source": [
    "dm.loadCurrentProject()\n",
    "classes = [ ('Class-1', \"cyan\"),\n",
    "            ('Class-2', \"green\"),\n",
    "            ('Class-3', \"magenta\"),\n",
    "            ('Class-4', \"blue\")]\n",
    "\n",
    "lm().setLabels( classes )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here we have the option to preprocess all image files (takes a long time if not done yet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if preprocess:\n",
    "    dm.prepare_inputs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here we define a custom CNN to use withing the spectraclass framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k6/40r5lsxs75g91q824qzfvqy40000gn/T/ipykernel_39020/265971139.py:4: UserWarning: Config option `nfeatures` not recognized by `ClassificationManager`.\n",
      "  cm().nepochs = 10\n",
      "2023-01-16 12:32:30.112724: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 363)]             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 182)               66248     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 91)                16653     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 46)                4232      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 60)                2820      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 120)               7320      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 240)               29040     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 363)               87483     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 213,796\n",
      "Trainable params: 213,796\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 363)]             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 182)               66248     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 91)                16653     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 46)                4232      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 30)                1410      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 88,543\n",
      "Trainable params: 88,543\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1389/1389 [==============================] - 1s 627us/step\n",
      "1389/1389 [==============================] - 1s 793us/step\n"
     ]
    }
   ],
   "source": [
    "from spectraclass.learn.mlp import MLP\n",
    "from spectraclass.learn.cnn import CNN2D, SpectralCNN, CNN3D\n",
    "\n",
    "cm().nepochs = 10\n",
    "cm().mid = \"mlp\"\n",
    "\n",
    "mlp = MLP( 'mlp', layers = [32, 16] )\n",
    "cm().addNetwork(mlp)\n",
    "\n",
    "cnn = CNN2D( 'cnn2d', cnn_layers =  [(8,3,1)], dense_layers= [32, 16] )\n",
    "cm().addNetwork(cnn)\n",
    "\n",
    "cnn1D = SpectralCNN( 'cnn1d', cnn_layers = [(8,5,3),(8,5,3)], dense_layers= [32, 16] )\n",
    "cm().addNetwork(cnn1D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here we start up the Spectraclass GUI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing GUI using controller <class 'spectraclass.gui.spatial.application.Spectraclass'>\n",
      "GUI Init complete\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf8544abfa754920b55dc16d9ddbcdac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(VBox(children=(HBox(children=(Button(description='Unlabeled', layout=Layout(bordâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "controller: SpectraclassController = app()\n",
    "controller.gui()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:spectraclass] *",
   "language": "python",
   "name": "conda-env-spectraclass-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}