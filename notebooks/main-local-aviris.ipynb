{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-17 19:45:44.168455: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "from spectraclass.data.base import DataManager\n",
    "from spectraclass.data.base import ModeDataManager\n",
    "from spectraclass.data.spatial.tile.manager import TileManager\n",
    "from spectraclass.data.spatial.modes import AvirisDataManager\n",
    "from spectraclass.application.controller import app, SpectraclassController\n",
    "from spectraclass.model.labels import LabelsManager, lm\n",
    "from spectraclass.learn.manager import ClassificationManager, cm\n",
    "from spectraclass.learn.base import LearningModel\n",
    "import os\n",
    "from typing import List, Union, Tuple, Optional, Dict, Callable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here we configure paths on the Jupyter server.  If these paths are not specified here then the default values,\n",
    "    defined in server-side config files, for the project (\"demo2\") and data mode (\"desis\"), will be used.  You can\n",
    "    choose whatever project names you want, they are used to save configurations and results for ongoing investigations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening log file:  '/Users/tpmaxwel/.spectraclass/logging/aviris/img_mgr.log'\n",
      "Using config file: '/Users/tpmaxwel/Development/Projects/spectraclass/defaults/config.py'\n",
      "Using config file: '/Users/tpmaxwel/.spectraclass/config/aviris/img_mgr.py'\n"
     ]
    }
   ],
   "source": [
    "dm: DataManager = DataManager.initialize( \"img_mgr\", 'aviris' )\n",
    "location = \"desktop\"\n",
    "if location == \"adapt\":\n",
    "    dm.modal.cache_dir = \"/adapt/nobackup/projects/ilab/cache\"\n",
    "    dm.modal.data_dir = \"/css/above/daac.ornl.gov/daacdata/above/ABoVE_Airborne_AVIRIS_NG/data/\"\n",
    "elif location == \"desktop\":\n",
    "    dm.modal.cache_dir = \"/Volumes/Shared/Cache\"\n",
    "    dm.modal.data_dir = \"/Users/tpmaxwel/Development/Data/Aviris\"\n",
    "else: raise Exception( f\"Unknown location: {location}\")\n",
    "    \n",
    "block_size = 150\n",
    "method = \"aec\" # \"vae\"\n",
    "model_dims = 24\n",
    "version = \"v2p9\"  # \"v2v2\" \"v2p9\"\n",
    "preprocess = False\n",
    "\n",
    "dm.use_model_data = True\n",
    "dm.proc_type = \"cpu\"\n",
    "dm.modal.images_glob = f\"ang2017*rfl/ang*_rfl_{version}/ang*_corr_{version}_img\"\n",
    "TileManager.block_size = block_size\n",
    "TileManager.block_index = [1,5]\n",
    "AvirisDataManager.version = version\n",
    "dm.modal.valid_aviris_bands = [[0,195],[210,287],[312,10000]]\n",
    "dm.modal.model_dims = model_dims\n",
    "dm.modal.reduce_method = method\n",
    "dm.modal.reduce_nepoch = 3\n",
    "dm.modal.reduce_focus_nepoch = 10\n",
    "dm.modal.reduce_niter = 1\n",
    "dm.modal.reduce_focus_ratio = 10.0\n",
    "dm.modal.reduce_dropout = 0.0\n",
    "dm.modal.reduce_learning_rate = 1e-4\n",
    "dm.modal.refresh_model = False\n",
    "dm.modal.modelkey = f\"b{block_size}.{method}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here we load the project data and define a set of class names (with associated colors) to be used in the classification process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Reading raster file /Users/tpmaxwel/Development/Data/Aviris/ang20170720t004130rfl/ang20170720t004130_rfl_v2p9/ang20170720t004130_corr_v2p9_img, dims = ('band', 'y', 'x'), shape = (425, 11746, 662)\n",
      "#Tile[0]-> Read Data: shape = (425, 11746, 662), dims=('band', 'y', 'x')\n"
     ]
    }
   ],
   "source": [
    "dm.loadCurrentProject()\n",
    "classes = [ ('Class-1', \"cyan\"),\n",
    "            ('Class-2', \"green\"),\n",
    "            ('Class-3', \"magenta\"),\n",
    "            ('Class-4', \"blue\")]\n",
    "\n",
    "lm().setLabels( classes )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here we have the option to preprocess all image files (takes a long time if not done yet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if preprocess:\n",
    "    dm.prepare_inputs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here we define a custom CNN to use withing the spectraclass framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k6/40r5lsxs75g91q824qzfvqy40000gn/T/ipykernel_76661/265971139.py:4: UserWarning: Config option `nfeatures` not recognized by `ClassificationManager`.\n",
      "  cm().nepochs = 10\n",
      "2023-01-17 19:45:52.394581: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Applications/anaconda3/envs/spectraclass-py3.9/lib/python3.9/site-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 391)]             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 196)               76832     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 98)                19306     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 49)                4851      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 48)                2400      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 96)                4704      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 192)               18624     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 384)               74112     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 391)               150535    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 351,364\n",
      "Trainable params: 351,364\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 391)]             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 196)               76832     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 98)                19306     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 49)                4851      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 24)                1200      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 102,189\n",
      "Trainable params: 102,189\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Autoencoder general training: 250 blocks for image[0/1]: ang20170720t004130rfl/ang20170720t004130_rfl_v2p9/ang20170720t004130_corr_v2p9_img\n",
      " ** ITER[<built-in function iter>]: Processing block(0, 0), data shape = (17657, 391)\n",
      "Epoch 1/3\n",
      "69/69 [==============================] - 1s 6ms/step - loss: 0.9941\n",
      "Epoch 2/3\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.9832\n",
      "Epoch 3/3\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.9669\n",
      " Trained autoencoder in 2.6110551357269287 sec\n",
      " ** ITER[<built-in function iter>]: Processing block(0, 1), data shape = (17657, 391)\n",
      "Epoch 4/6\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 0.9381\n",
      "Epoch 5/6\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 0.8889\n",
      "Epoch 6/6\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 0.7954\n",
      " Trained autoencoder in 1.3595588207244873 sec\n",
      " ** ITER[<built-in function iter>]: Processing block(0, 2), data shape = (17657, 391)\n",
      "Epoch 7/9\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 0.6060\n",
      "Epoch 8/9\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 0.3622\n",
      "Epoch 9/9\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 0.2919\n",
      " Trained autoencoder in 1.3487257957458496 sec\n",
      " ** ITER[<built-in function iter>]: Processing block(0, 3), data shape = (17657, 391)\n",
      "Epoch 10/12\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 0.2720\n",
      "Epoch 11/12\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 0.2577\n",
      "Epoch 12/12\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.2503\n",
      " Trained autoencoder in 1.3793280124664307 sec\n",
      " ** ITER[<built-in function iter>]: Processing block(0, 4), data shape = (17657, 391)\n",
      "Epoch 13/15\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 0.2480\n",
      "Epoch 14/15\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 0.2476\n",
      "Epoch 15/15\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 0.2475\n",
      " Trained autoencoder in 1.3658158779144287 sec\n",
      " ** ITER[<built-in function iter>]: Processing block(0, 5), data shape = (17657, 391)\n",
      "Epoch 16/18\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 0.2475\n",
      "Epoch 17/18\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 0.2476\n",
      "Epoch 18/18\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 0.2475\n",
      " Trained autoencoder in 1.356694221496582 sec\n",
      " ** ITER[<built-in function iter>]: Processing block(0, 6), data shape = (17657, 391)\n",
      "Epoch 19/21\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 0.2475\n",
      "Epoch 20/21\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 0.2475\n",
      "Epoch 21/21\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.2475\n",
      " Trained autoencoder in 1.380582332611084 sec\n",
      " ** ITER[<built-in function iter>]: Processing block(0, 7), data shape = (17657, 391)\n",
      "Epoch 22/24\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.2475\n",
      "Epoch 23/24\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.2475\n",
      "Epoch 24/24\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.2475\n",
      " Trained autoencoder in 1.468045949935913 sec\n",
      " ** ITER[<built-in function iter>]: Processing block(0, 8), data shape = (17657, 391)\n",
      "Epoch 25/27\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.2475\n",
      "Epoch 26/27\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.2475\n",
      "Epoch 27/27\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.2475\n",
      " Trained autoencoder in 1.4453728199005127 sec\n",
      " ** ITER[<built-in function iter>]: Processing block(0, 9), data shape = (17657, 391)\n",
      "Epoch 28/30\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.2475\n",
      "Epoch 29/30\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.2475\n",
      "Epoch 30/30\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.2475\n",
      " Trained autoencoder in 1.426868200302124 sec\n",
      " ** ITER[<built-in function iter>]: Processing block(0, 10), data shape = (17657, 391)\n",
      "Epoch 31/33\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.2476\n",
      "Epoch 32/33\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.2475\n",
      "Epoch 33/33\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.2476\n",
      " Trained autoencoder in 1.4612557888031006 sec\n",
      " ** ITER[<built-in function iter>]: Processing block(0, 11), data shape = (17657, 391)\n",
      "Epoch 34/36\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.2475\n",
      "Epoch 35/36\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.2476\n",
      "Epoch 36/36\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.2475\n",
      " Trained autoencoder in 1.4120118618011475 sec\n",
      " ** ITER[<built-in function iter>]: Processing block(0, 12), data shape = (17657, 391)\n",
      "Epoch 37/39\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.2475\n",
      "Epoch 38/39\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.2475\n",
      "Epoch 39/39\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.2475\n",
      " Trained autoencoder in 1.3942382335662842 sec\n",
      " ** ITER[<built-in function iter>]: Processing block(0, 13), data shape = (17657, 391)\n",
      "Epoch 40/42\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.2475\n",
      "Epoch 41/42\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.2475\n",
      "Epoch 42/42\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.2475\n",
      " Trained autoencoder in 1.448023796081543 sec\n",
      " ** ITER[<built-in function iter>]: Processing block(0, 14), data shape = (17657, 391)\n",
      "Epoch 43/45\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.2475\n",
      "Epoch 44/45\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.2475\n",
      "Epoch 45/45\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.2475\n",
      " Trained autoencoder in 1.4870922565460205 sec\n",
      " ** ITER[<built-in function iter>]: Processing block(0, 15), data shape = (17657, 391)\n",
      "Epoch 46/48\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.2475\n",
      "Epoch 47/48\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.2475\n",
      "Epoch 48/48\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.2475\n",
      " Trained autoencoder in 1.4202969074249268 sec\n",
      " ** ITER[<built-in function iter>]: Processing block(0, 16), data shape = (17657, 391)\n",
      "Epoch 49/51\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.2475\n",
      "Epoch 50/51\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.2475\n",
      "Epoch 51/51\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.2475\n",
      " Trained autoencoder in 1.4333882331848145 sec\n",
      " ** ITER[<built-in function iter>]: Processing block(0, 17), data shape = (17657, 391)\n",
      "Epoch 52/54\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.2475\n",
      "Epoch 53/54\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.2476\n",
      "Epoch 54/54\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.2475\n",
      " Trained autoencoder in 1.4327080249786377 sec\n",
      " ** ITER[<built-in function iter>]: Processing block(0, 18), data shape = (17657, 391)\n",
      "Epoch 55/57\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.2475\n",
      "Epoch 56/57\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.2475\n",
      "Epoch 57/57\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.2475\n",
      " Trained autoencoder in 1.445662021636963 sec\n",
      " ** ITER[<built-in function iter>]: Processing block(0, 19), data shape = (17657, 391)\n",
      "Epoch 58/60\n",
      "69/69 [==============================] - 0s 5ms/step - loss: 0.2475\n",
      "Epoch 59/60\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.2476\n",
      "Epoch 60/60\n",
      "10/69 [===>..........................] - ETA: 0s - loss: 0.2431"
     ]
    }
   ],
   "source": [
    "from spectraclass.learn.mlp import MLP\n",
    "from spectraclass.learn.cnn import CNN2D, SpectralCNN, CNN3D\n",
    "\n",
    "cm().nepochs = 10\n",
    "cm().mid = \"mlp\"\n",
    "\n",
    "mlp = MLP( 'mlp', layers = [32, 16] )\n",
    "cm().addNetwork(mlp)\n",
    "\n",
    "cnn = CNN2D( 'cnn2d', cnn_layers =  [(8,3,1)], dense_layers= [32, 16] )\n",
    "cm().addNetwork(cnn)\n",
    "\n",
    "cnn1D = SpectralCNN( 'cnn1d', cnn_layers = [(8,5,3),(8,5,3)], dense_layers= [32, 16] )\n",
    "cm().addNetwork(cnn1D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here we start up the Spectraclass GUI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "controller: SpectraclassController = app()\n",
    "controller.gui()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:spectraclass-py3.9] *",
   "language": "python",
   "name": "conda-env-spectraclass-py3.9-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}