{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-27 13:16:00.478075: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "from spectraclass.data.base import DataManager\n",
    "from spectraclass.data.spatial.tile.manager import TileManager\n",
    "from spectraclass.application.controller import app, SpectraclassController\n",
    "from spectraclass.model.labels import LabelsManager, lm\n",
    "from spectraclass.learn.manager import ClassificationManager, cm\n",
    "from spectraclass.data.base import ModeDataManager\n",
    "from spectraclass.data.spatial.modes import AvirisDataManager\n",
    "from typing import List, Union, Tuple, Optional, Dict, Callable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we configure paths on the Jupyter server.  If these paths are not specified here then the default values,\n",
    "    defined in server-side config files, for the project (\"demo2\") and data mode (\"desis\"), will be used.  You can\n",
    "    choose whatever project names you want, they are used to save configurations and results for ongoing investigations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening log file:  '/home/tpmaxwel/.spectraclass/logging/aviris/img_mgr.log'\n",
      "Using config file: '/panfs/ccds02/home/tpmaxwel/JupyterLinks/spectraclass-dev/defaults/config.py'\n",
      "Using config file: '/home/tpmaxwel/.spectraclass/config/aviris/img_mgr.py'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/panfs/ccds02/app/modules/jupyter/ilab/tensorflow-kernel/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3194: UserWarning: Config option `use_model_data` not recognized by `DataManager`.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "/panfs/ccds02/home/tpmaxwel/JupyterLinks/spectraclass-dev/notebooks/spectraclass/model/base.py:26: UserWarning: Config option `reduce_target_block` not recognized by `AvirisDataManager`.  Did you mean one of: `reduce_method, reduce_nblocks, reduce_nepoch`?\n",
      "  inst = cls(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "dm: DataManager = DataManager.initialize( \"AGB\", 'neon' )\n",
    "\n",
    "\n",
    "dm.modal.cache_dir = \"/explore/nobackup/projects/ilab/cache\"\n",
    "dm.modal.data_dir  = \"/explore/nobackup/projects/ilab/data\"\n",
    "\n",
    "block_size = 150\n",
    "method = \"aec\" # \"vae\"\n",
    "model_dims = 32\n",
    "year= 2015\n",
    "version = \"beta_pmm\"\n",
    "roi = \"541567.6_4136443.0_542567.6_4137443.0\"\n",
    "\n",
    "dm.modal.ext =  \"_img\"\n",
    "dm.proc_type = \"cpu\"\n",
    "dm.modal.images_glob = f\"AGB/test/{version}/MLBS_{year}_{roi}/MLBS_{year}_Reflectance_reflectance_warp.tif\"\n",
    "TileManager.block_size = block_size\n",
    "TileManager.reprocess = False\n",
    "dm.modal.model_dims = model_dims\n",
    "dm.modal.reduce_method = method\n",
    "dm.modal.reduce_nepoch = 2\n",
    "dm.modal.reduce_focus_nepoch = 0\n",
    "dm.modal.reduce_niter = 12\n",
    "dm.modal.reduce_focus_ratio = 10.0\n",
    "dm.modal.reduce_dropout = 0.0\n",
    "dm.modal.reduce_learning_rate = 1e-4\n",
    "dm.modal.refresh_model = True\n",
    "dm.modal.reduce_nblocks = 1000\n",
    "dm.modal.reduce_nimages = 100\n",
    "dm.modal.modelkey = f\"b{block_size}.{version}.{year}.{roi}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we load the project data and define a set of class names and associated colors to be used in the classification process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Reading raster file /css/above/daac.ornl.gov/daacdata/above/ABoVE_Airborne_AVIRIS_NG/data//ang20190801t150124rfl/ang20190801t150124_rfl_v2v2/ang20190801t150124_corr_v2v2_img, dims = ('band', 'y', 'x'), shape = (425, 14400, 724)\n",
      "#Tile[0]-> Read Data: shape = (425, 14400, 724), dims=('band', 'y', 'x')\n"
     ]
    }
   ],
   "source": [
    "dm.loadCurrentProject()\n",
    "classes = [ ('Class-1', \"cyan\"),\n",
    "            ('Class-2', \"green\"),\n",
    "            ('Class-3', \"magenta\"),\n",
    "            ('Class-4', \"blue\")]\n",
    "\n",
    "lm().setLabels( classes )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Custom CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2789978/3003413587.py:4: UserWarning: Config option `nfeatures` not recognized by `ClassificationManager`.\n",
      "  cm().nepochs = 20\n",
      "/tmp/ipykernel_2789978/3003413587.py:4: UserWarning: Config option `cnn_layers` not recognized by `ClassificationManager`.\n",
      "  cm().nepochs = 20\n",
      "/tmp/ipykernel_2789978/3003413587.py:4: UserWarning: Config option `dense_layers` not recognized by `ClassificationManager`.\n",
      "  cm().nepochs = 20\n",
      "2023-01-27 13:16:33.261316: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 363)]             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 182)               66248     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 91)                16653     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 46)                4232      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                3008      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 363)               93291     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 224,776\n",
      "Trainable params: 224,776\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 363)]             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 182)               66248     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 91)                16653     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 46)                4232      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                1504      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 88,637\n",
      "Trainable params: 88,637\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "784/784 [==============================] - 1s 586us/step\n",
      "784/784 [==============================] - 1s 696us/step\n"
     ]
    }
   ],
   "source": [
    "from spectraclass.learn.mlp import MLP\n",
    "from spectraclass.learn.cnn import CNN2D, SpectralCNN, CNN3D\n",
    "\n",
    "cm().nepochs = 20\n",
    "cm().mid = \"mlp\"\n",
    "\n",
    "mlp = MLP( 'mlp', layers = [32, 16] )\n",
    "cm().addNetwork(mlp)\n",
    "\n",
    "cnn = CNN2D( 'cnn2d', cnn_layers =  [(8,3,1)], dense_layers= [32, 16] )\n",
    "cm().addNetwork(cnn)\n",
    "\n",
    "cnn1D = SpectralCNN( 'cnn1d', cnn_layers = [(8,5,3),(8,5,3)], dense_layers= [32, 16] )\n",
    "cm().addNetwork(cnn1D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we start up the Spectraclass GUI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing GUI using controller <class 'spectraclass.gui.spatial.application.Spectraclass'>\n",
      "GUI Init complete\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd259ceb504c4d01be4fbfc4883eaff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(VBox(children=(HBox(children=(Button(description='Unlabeled', layout=Layout(bord…"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "controller: SpectraclassController = app()\n",
    "controller.gui()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ILAB Kernel (TensorFlow)",
   "language": "python",
   "name": "tensorflow-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
