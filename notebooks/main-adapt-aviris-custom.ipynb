{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from spectraclass.data.base import DataManager\n",
    "from spectraclass.data.base import ModeDataManager\n",
    "from spectraclass.data.spatial.tile.manager import TileManager\n",
    "from spectraclass.data.spatial.modes import AvirisDataManager\n",
    "from spectraclass.application.controller import app, SpectraclassController\n",
    "from spectraclass.model.labels import LabelsManager, lm\n",
    "from spectraclass.learn.manager import ClassificationManager, cm\n",
    "from spectraclass.learn.base import LearningModel\n",
    "import os\n",
    "from typing import List, Union, Tuple, Optional, Dict, Callable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here we configure paths on the Jupyter server.  If these paths are not specified here then the default values,\n",
    "    defined in server-side config files, for the project (\"demo2\") and data mode (\"desis\"), will be used.  You can\n",
    "    choose whatever project names you want, they are used to save configurations and results for ongoing investigations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening log file:  '/Users/tpmaxwel/.spectraclass/logging/aviris/img_mgr.log'\n",
      "Using config file: '/Users/tpmaxwel/Development/Projects/spectraclass/defaults/config.py'\n",
      "Using config file: '/Users/tpmaxwel/.spectraclass/config/aviris/img_mgr.py'\n"
     ]
    }
   ],
   "source": [
    "dm: DataManager = DataManager.initialize( \"img_mgr\", 'aviris' )\n",
    "location = \"adapt\"\n",
    "if location == \"adapt\":\n",
    "    dm.modal.cache_dir = \"/explore/nobackup/projects/ilab/cache\"\n",
    "    dm.modal.data_dir = \"/css/above/daac.ornl.gov/daacdata/above/ABoVE_Airborne_AVIRIS_NG/data/\"\n",
    "    dm.modal.images_glob =  \"ang20170731t222832rfl/ang*_rfl_v2p9/ang*_corr_v2p9.tif\"\n",
    "elif location == \"desktop\":\n",
    "    dm.modal.cache_dir = \"/Volumes/Shared/Cache\"\n",
    "    dm.modal.data_dir = \"/Users/tpmaxwel/Development/Data/Aviris\"\n",
    "else: raise Exception( f\"Unknown location: {location}\")\n",
    "\n",
    "block_size = 150\n",
    "method = \"aec\" # \"vae\"\n",
    "model_dims = 32\n",
    "    \n",
    "dm.modal.ext =  \"_img\"\n",
    "dm.use_model_data = True\n",
    "dm.proc_type = \"skl\"\n",
    "TileManager.block_size = block_size\n",
    "TileManager.block_index = [0,7]\n",
    "dm.modal.valid_aviris_bands = [ [5,193], [214,283], [319,10000] ]\n",
    "dm.modal.model_dims = model_dims\n",
    "dm.modal.reduce_method = method\n",
    "dm.modal.reduce_nepoch = 3\n",
    "dm.modal.reduce_focus_nepoch = 10\n",
    "dm.modal.reduce_niter = 1\n",
    "dm.modal.reduce_focus_ratio = 10.0\n",
    "dm.modal.reduce_dropout = 0.0\n",
    "dm.modal.reduce_learning_rate = 1e-4\n",
    "dm.modal.refresh_model = False\n",
    "dm.modal.modelkey = f\"b{block_size}.{method}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here we load the project data and define a set of class names (with associated colors) to be used in the classification process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Reading raster file /Users/tpmaxwel/Development/Data/Aviris/ang20170720t004130rfl/ang20170720t004130_rfl_v2p9/ang20170720t004130_corr_v2p9_img, dims = ('band', 'y', 'x'), shape = (425, 11746, 662)\n",
      "#Tile[0]-> Read Data: shape = (425, 11746, 662), dims=('band', 'y', 'x')\n",
      " Preparing inputs\n",
      "Completed Reading raster file /Users/tpmaxwel/Development/Data/Aviris/ang20170720t004130rfl/ang20170720t004130_rfl_v2p9/ang20170720t004130_corr_v2p9_img, dims = ('band', 'y', 'x'), shape = (425, 11746, 662)\n",
      "#Tile[0]-> Read Data: shape = (425, 11746, 662), dims=('band', 'y', 'x')\n",
      " ---> Writing metadata file at /Volumes/Shared/Cache/spectraclass/aviris/img_mgr/b150.aec.mdata.txt\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 363)]             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 182)               66248     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 91)                16653     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 46)                4232      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                3008      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 363)               93291     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 224,776\n",
      "Trainable params: 224,776\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 363)]             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 182)               66248     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 91)                16653     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 46)                4232      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32)                1504      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 88,637\n",
      "Trainable params: 88,637\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-22 16:13:26.555288: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "dm.loadCurrentProject()\n",
    "classes = [ ('Class-1', \"cyan\"),\n",
    "            ('Class-2', \"green\"),\n",
    "            ('Class-3', \"magenta\"),\n",
    "            ('Class-4', \"blue\")]\n",
    "\n",
    "lm().setLabels( classes )\n",
    "dm.modal.initialize_dimension_reduction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here we define a custom CNN to use withing the spectraclass framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: ram://6c31cddd-d741-45db-b580-6cbf766d9cb4/assets\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://4a7c0463-63ae-4cce-a12c-0615566d86fb/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://4a7c0463-63ae-4cce-a12c-0615566d86fb/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640/640 [==============================] - 0s 667us/step\n",
      "640/640 [==============================] - 1s 839us/step\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://a6b72000-e200-4dee-8ee1-5edd327a3639/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://a6b72000-e200-4dee-8ee1-5edd327a3639/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from spectraclass.learn.models.network import Network, ModelType\n",
    "\n",
    "class CNN(Network):\n",
    "    TYPE = ModelType.SPATIAL\n",
    "\n",
    "    def _build_model(self, **kwargs) -> Tuple[Model,Dict]:\n",
    "        from spectraclass.learn.models.spatial import SpatialModelWrapper\n",
    "        nfeatures = kwargs.pop('nfeatures', 32 )\n",
    "        from spectraclass.model.labels import lm\n",
    "        input_shape = SpatialModelWrapper.get_input_shape()\n",
    "        nclasses = lm().nLabels\n",
    "        ks = kwargs.pop('kernel_size',3)\n",
    "        model = models.Sequential()\n",
    "        model.add( Input( shape=input_shape ) )\n",
    "        model.add( layers.Conv2D( nfeatures, (ks,ks), activation='relu', padding=\"same\" ) )\n",
    "        model.add( layers.Reshape( SpatialModelWrapper.flatten(input_shape,nfeatures) ) )\n",
    "        model.add( layers.Dense( nfeatures, activation='relu' ) )\n",
    "        model.add( layers.Dense( nclasses, activation='softmax' ) )\n",
    "        return model, kwargs\n",
    "\n",
    "cm().addNetwork( CNN( 'cnn-1', nfeatures=64, nepochs=200, test_size=0.1 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here we start up the Spectraclass GUI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing GUI using controller <class 'spectraclass.gui.spatial.application.Spectraclass'>\n",
      "UMAP.init: model_data('samples', 'band') shape = (20464, 32)\n",
      "Get Activation flow for dsid 20170720t004130-0-7\n",
      "ActivationFlow.instance: shape=(20464, 32), nn=5, args={'metric': 'cosine', 'p': 2}\n",
      " --->  $$$D: setNodeData D=> <class 'numpy.ndarray'>:float32\n",
      "Computed NN skGraph with 5 neighbors and 20464 verts in 11.935975074768066 sec (0.1989329179128011 min)\n",
      " --->  $$$D: setNodeData D=> <class 'numpy.ndarray'>:float32\n",
      "Computed NN skGraph with 5 neighbors and 20464 verts in 8.776397943496704 sec (0.1462732990582784 min)\n",
      "Get Activation flow for dsid 20170720t004130-0-7\n",
      "Get Activation flow for dsid 20170720t004130-0-7\n",
      "Computing umap embedding with nepochs = 1, alpha = 1.0, nLabels = 0, n_neighbors = 5, init = random (random)\n",
      "Completed UMAP random initialization, init shape = (20464, 3)\n",
      "Completed simplicial_set_embedding, times = 0.0002348621686299642 4.553794860839844e-06 min\n",
      "umap embedding complete, result shape = (20464, 3), time = 0.014577865600585938 \n",
      "GUI Init complete\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10e49b4dfcb840839c5c867c367cb56f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(VBox(children=(HBox(children=(Button(description='Unlabeled', layout=Layout(bordâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "controller: SpectraclassController = app()\n",
    "controller.gui()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:spectraclass] *",
   "language": "python",
   "name": "conda-env-spectraclass-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}