{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, numpy as np, torch\n",
    "from typing import List, Union, Tuple, Optional, Dict, Callable\n",
    "from pynndescent import NNDescent\n",
    "from spectraclass.data.base import DataManager\n",
    "from spectraclass.graph.manager import ActivationFlow, ActivationFlowManager, afm\n",
    "import hvplot.xarray\n",
    "import holoviews as hv\n",
    "from torch\n",
    "from spectraclass.learn.gcn import GCN\n",
    "from spectraclass.learn.mlp import MLP\n",
    "import panel as pn\n",
    "from torch_geometric.data import Data\n",
    "import xarray as xa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading config files: ['indianPines.py'] from dir /Users/tpmaxwel/.spectraclass/config/aviris\n",
      "Opening log file:  '/Users/tpmaxwel/.spectraclass/logging/aviris/indianPines.5186.log'\n",
      "Get Activation flow for dsid aviris_hyperspectral_data/19920612_AVIRIS_IndianPine_Site3.1000-1000_0-0_b-1000-1000-0-0-Autoencoder-32\n",
      "\n",
      "Reading class file: /Users/tpmaxwel/GDrive/Tom/Data/Aviris/IndianPines/documentation/Site3_Project_and_Ground_Reference_Files/19920612_AVIRIS_IndianPine_Site3_gr.tif\n",
      "\n",
      "raw_spectral_data shape = (220, 145, 145)\n",
      "reduced_spectral_data shape = (21025, 32)\n",
      "num_nodes = 21025\n",
      "num_edges = 105125\n",
      "num_node_features = 32\n",
      "num_edge_features = 0\n",
      "contains_isolated_nodes = False\n",
      "contains_self_loops = True\n",
      "is_directed = True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k6/40r5lsxs75g91q824qzfvqy40000gn/T/ipykernel_5186/2137861215.py:21: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  class_data: torch.tensor = torch.from_numpy( class_map.values.flatten().astype( np.long ) ) - 1\n"
     ]
    }
   ],
   "source": [
    "view_band = 10\n",
    "use_edge_weights = False\n",
    "\n",
    "dm: DataManager = DataManager.initialize( \"indianPines\", 'aviris' )\n",
    "project_data: xa.Dataset = dm.loadCurrentProject( \"main\" )\n",
    "flow: ActivationFlow = afm().getActivationFlow()\n",
    "graph: NNDescent = flow.getGraph()\n",
    "D: np.ndarray = graph.neighbor_graph[1].flatten()\n",
    "reduced_spectral_data: xa.DataArray = project_data['reduction']\n",
    "raw_spectral_data: xa.DataArray = project_data['raw']\n",
    "class_map: xa.DataArray = dm.getClassMap()\n",
    "edge_weights = GCN.calc_edge_weights( D ) if use_edge_weights else None\n",
    "[ny,nx] = raw_spectral_data.shape[1:]\n",
    "I: np.array = np.array( range( ny*nx ) )\n",
    "X, Y = I % nx, I // nx\n",
    "from torch_geometric.transforms import KNNGraph\n",
    "edge_attr: torch.tensor  = torch.from_numpy( D.reshape( D.size, 1 ) )\n",
    "edge_index: torch.tensor = flow.getEdgeIndex()\n",
    "node_data: torch.tensor = torch.from_numpy( reduced_spectral_data.values )\n",
    "pos: torch.tensor = torch.from_numpy( np.vstack( [Y,X] ).transpose() )\n",
    "class_data: torch.tensor = torch.from_numpy( class_map.values.flatten().astype( np.long ) ) - 1\n",
    "graph_data = Data( x=node_data, y=class_data, pos=pos, edge_index=edge_index, edge_weights=edge_weights )\n",
    "nfeatures = graph_data.num_node_features\n",
    "\n",
    "print( f\"raw_spectral_data shape = {raw_spectral_data.shape}\")\n",
    "print( f\"reduced_spectral_data shape = {reduced_spectral_data.shape}\")\n",
    "print( f\"num_nodes = {graph_data.num_nodes}\")\n",
    "print( f\"num_edges = {graph_data.num_edges}\")\n",
    "print( f\"num_node_features = {nfeatures}\")\n",
    "print( f\"num_edge_features = {graph_data.num_edge_features}\")\n",
    "print( f\"contains_isolated_nodes = {graph_data.contains_isolated_nodes()}\")\n",
    "print( f\"contains_self_loops = {graph_data.contains_self_loops()}\")\n",
    "print( f\"is_directed = {graph_data.is_directed()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# band_image_data: np.ndarray = reduced_spectral_data.values[:,view_band].reshape( [1] + list(raw_spectral_data.shape[1:]) )\n",
    "# band_image: xa.DataArray = class_map.copy( True, band_image_data )\n",
    "# class_plot = class_map.hvplot.image( cmap='Category20', clim=(0, 20) )\n",
    "# band_plot = band_image.hvplot.image( cmap='jet', clim=( -1.5, 1.5 ) )\n",
    "# pn.Row( class_plot, band_plot  ).show(\"Indian Pines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "Data(edge_index=[2, 105125], test_mask=[21025], train_mask=[21025], x=[21025, 32], y=[21025])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_transform = KNNGraph(4)\n",
    "num_class_exemplars = 5\n",
    "class_data: np.ndarray = class_map.values.flatten()\n",
    "nclasses: int = class_map.values.max()\n",
    "class_masks: List[np.ndarray] = [ (class_data == (iC+1) ) for iC in range(nclasses) ]\n",
    "test_mask: np.ndarray = (class_data > 0)\n",
    "nodata_mask = np.logical_not( test_mask )\n",
    "class_indices = [ np.argwhere(class_masks[iC]).flatten() for iC in range(nclasses) ]\n",
    "train_class_indices = [  np.random.choice(class_indices[iC], size=num_class_exemplars, replace=False )  for iC in range(nclasses)  ]\n",
    "train_indices = np.hstack( train_class_indices )\n",
    "train_mask = np.full( [ node_data.shape[0] ], False, dtype=bool )\n",
    "train_mask[ train_indices ] = True\n",
    "test_mask[ train_indices ] = False\n",
    "\n",
    "graph_data['train_mask'] = torch.from_numpy( train_mask )\n",
    "graph_data['test_mask'] = torch.from_numpy( test_mask )\n",
    "graph_data['nodata_mask'] = torch.from_numpy( nodata_mask )\n",
    "graph_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with lr=0.02, weight_decay=0.0005, nepochs=1000, dropout=True\n",
      "epoch: 0, loss = 3.27402925491333\n",
      "epoch: 25, loss = 1.1978318691253662\n",
      "epoch: 50, loss = 0.8777629137039185\n",
      "epoch: 75, loss = 0.801292896270752\n",
      "epoch: 100, loss = 0.7167412042617798\n",
      "epoch: 125, loss = 0.6534552574157715\n",
      "epoch: 150, loss = 0.6655129790306091\n",
      "epoch: 175, loss = 0.5843487977981567\n",
      "epoch: 200, loss = 0.5623810887336731\n",
      "epoch: 225, loss = 0.5817524194717407\n",
      "epoch: 250, loss = 0.5197635889053345\n",
      "epoch: 275, loss = 0.4757311940193176\n",
      "epoch: 300, loss = 0.5555009245872498\n",
      "epoch: 325, loss = 0.531602680683136\n",
      "epoch: 350, loss = 0.55058753490448\n",
      "epoch: 375, loss = 0.41903916001319885\n",
      "epoch: 400, loss = 0.4557510018348694\n",
      "epoch: 425, loss = 0.45506247878074646\n",
      "epoch: 450, loss = 0.42208462953567505\n",
      "epoch: 475, loss = 0.4218785762786865\n",
      "epoch: 500, loss = 0.4339276850223541\n",
      "epoch: 525, loss = 0.3204771876335144\n",
      "epoch: 550, loss = 0.38203054666519165\n",
      "epoch: 575, loss = 0.4494887888431549\n",
      "epoch: 600, loss = 0.407658189535141\n",
      "epoch: 625, loss = 0.4184526801109314\n",
      "epoch: 650, loss = 0.42639389634132385\n",
      "epoch: 675, loss = 0.4828318655490875\n",
      "epoch: 700, loss = 0.31752315163612366\n",
      "epoch: 725, loss = 0.41134604811668396\n",
      "epoch: 750, loss = 0.3814234137535095\n",
      "epoch: 775, loss = 0.4052761197090149\n",
      "epoch: 800, loss = 0.3855629861354828\n",
      "epoch: 825, loss = 0.36310476064682007\n",
      "epoch: 850, loss = 0.3218971788883209\n",
      "epoch: 875, loss = 0.340740442276001\n",
      "epoch: 900, loss = 0.3508433997631073\n",
      "epoch: 925, loss = 0.3560981750488281\n",
      "epoch: 950, loss = 0.36213549971580505\n",
      "epoch: 975, loss = 0.35236141085624695\n",
      " --> Accuracy: 0.4505\n",
      "Training model with lr=0.02, weight_decay=0.0005, nepochs=1000, dropout=True\n",
      "epoch: 0, loss = 3.0675597190856934\n",
      "epoch: 25, loss = 1.3262455463409424\n",
      "epoch: 50, loss = 0.9520651698112488\n",
      "epoch: 75, loss = 0.7909566164016724\n",
      "epoch: 100, loss = 0.7173944711685181\n",
      "epoch: 125, loss = 0.6223227977752686\n",
      "epoch: 150, loss = 0.667021632194519\n",
      "epoch: 175, loss = 0.6695462465286255\n",
      "epoch: 200, loss = 0.6252473592758179\n",
      "epoch: 225, loss = 0.5352975726127625\n",
      "epoch: 250, loss = 0.504713237285614\n",
      "epoch: 275, loss = 0.5322974920272827\n",
      "epoch: 300, loss = 0.49981099367141724\n",
      "epoch: 325, loss = 0.46267080307006836\n",
      "epoch: 350, loss = 0.4134414792060852\n",
      "epoch: 375, loss = 0.5179756283760071\n",
      "epoch: 400, loss = 0.40919724106788635\n",
      "epoch: 425, loss = 0.4477030336856842\n",
      "epoch: 450, loss = 0.47266802191734314\n",
      "epoch: 475, loss = 0.3931361138820648\n",
      "epoch: 500, loss = 0.41545015573501587\n",
      "epoch: 525, loss = 0.3804125189781189\n",
      "epoch: 550, loss = 0.35931360721588135\n",
      "epoch: 575, loss = 0.4201447069644928\n",
      "epoch: 600, loss = 0.40903550386428833\n",
      "epoch: 625, loss = 0.4314866065979004\n",
      "epoch: 650, loss = 0.4111432433128357\n",
      "epoch: 675, loss = 0.3508944809436798\n",
      "epoch: 700, loss = 0.4130778908729553\n",
      "epoch: 725, loss = 0.3536933362483978\n",
      "epoch: 750, loss = 0.3771617114543915\n",
      "epoch: 775, loss = 0.36970168352127075\n",
      "epoch: 800, loss = 0.3688296973705292\n",
      "epoch: 825, loss = 0.38153010606765747\n",
      "epoch: 850, loss = 0.432939350605011\n",
      "epoch: 875, loss = 0.34438902139663696\n",
      "epoch: 900, loss = 0.3413434326648712\n",
      "epoch: 925, loss = 0.39534199237823486\n",
      "epoch: 950, loss = 0.3071322441101074\n",
      "epoch: 975, loss = 0.31586962938308716\n",
      " --> Accuracy: 0.4548\n",
      "Training model with lr=0.02, weight_decay=0.0005, nepochs=1000, dropout=True\n",
      "epoch: 0, loss = 3.085092782974243\n",
      "epoch: 25, loss = 1.2342814207077026\n",
      "epoch: 50, loss = 0.8989465832710266\n",
      "epoch: 75, loss = 0.7863126993179321\n",
      "epoch: 100, loss = 0.6778371334075928\n",
      "epoch: 125, loss = 0.7103441953659058\n",
      "epoch: 150, loss = 0.6096113920211792\n",
      "epoch: 175, loss = 0.604282557964325\n",
      "epoch: 200, loss = 0.5238226652145386\n",
      "epoch: 225, loss = 0.5455266237258911\n",
      "epoch: 250, loss = 0.5073872804641724\n",
      "epoch: 275, loss = 0.46122241020202637\n",
      "epoch: 300, loss = 0.4835473895072937\n",
      "epoch: 325, loss = 0.4633609354496002\n",
      "epoch: 350, loss = 0.41365569829940796\n",
      "epoch: 375, loss = 0.44517794251441956\n",
      "epoch: 400, loss = 0.4376632571220398\n",
      "epoch: 425, loss = 0.39640119671821594\n",
      "epoch: 450, loss = 0.4672081470489502\n",
      "epoch: 475, loss = 0.35954779386520386\n",
      "epoch: 500, loss = 0.35144931077957153\n",
      "epoch: 525, loss = 0.35453468561172485\n",
      "epoch: 550, loss = 0.36762866377830505\n",
      "epoch: 575, loss = 0.3770272135734558\n",
      "epoch: 600, loss = 0.34842750430107117\n",
      "epoch: 625, loss = 0.3909420669078827\n",
      "epoch: 650, loss = 0.35064178705215454\n",
      "epoch: 675, loss = 0.3315850496292114\n",
      "epoch: 700, loss = 0.2988571524620056\n",
      "epoch: 725, loss = 0.29300153255462646\n",
      "epoch: 750, loss = 0.30964183807373047\n",
      "epoch: 775, loss = 0.2863095998764038\n",
      "epoch: 800, loss = 0.31448695063591003\n",
      "epoch: 825, loss = 0.3091356158256531\n",
      "epoch: 850, loss = 0.3492828905582428\n",
      "epoch: 875, loss = 0.3770025670528412\n",
      "epoch: 900, loss = 0.29249855875968933\n",
      "epoch: 925, loss = 0.27276021242141724\n",
      "epoch: 950, loss = 0.36877816915512085\n",
      "epoch: 975, loss = 0.37280234694480896\n",
      " --> Accuracy: 0.4623\n",
      "Training model with lr=0.02, weight_decay=0.0005, nepochs=1000, dropout=True\n",
      "epoch: 0, loss = 3.116797924041748\n",
      "epoch: 25, loss = 1.2729662656784058\n",
      "epoch: 50, loss = 0.9755728840827942\n",
      "epoch: 75, loss = 0.8739439845085144\n",
      "epoch: 100, loss = 0.6830459833145142\n",
      "epoch: 125, loss = 0.6170059442520142\n",
      "epoch: 150, loss = 0.5791320204734802\n",
      "epoch: 175, loss = 0.6323389410972595\n",
      "epoch: 200, loss = 0.6556185483932495\n",
      "epoch: 225, loss = 0.5431505441665649\n",
      "epoch: 250, loss = 0.4555531144142151\n",
      "epoch: 275, loss = 0.5603562593460083\n",
      "epoch: 300, loss = 0.5131309032440186\n",
      "epoch: 325, loss = 0.5375506281852722\n",
      "epoch: 350, loss = 0.4486779570579529\n",
      "epoch: 375, loss = 0.5650709867477417\n",
      "epoch: 400, loss = 0.43158087134361267\n",
      "epoch: 425, loss = 0.4299222528934479\n",
      "epoch: 450, loss = 0.3731478154659271\n",
      "epoch: 475, loss = 0.416220486164093\n",
      "epoch: 500, loss = 0.42737340927124023\n",
      "epoch: 525, loss = 0.3524573743343353\n",
      "epoch: 550, loss = 0.42243748903274536\n",
      "epoch: 575, loss = 0.33939433097839355\n",
      "epoch: 600, loss = 0.3641580641269684\n",
      "epoch: 625, loss = 0.4320529103279114\n",
      "epoch: 650, loss = 0.3690641522407532\n",
      "epoch: 675, loss = 0.40575870871543884\n",
      "epoch: 700, loss = 0.3479313254356384\n",
      "epoch: 725, loss = 0.38731566071510315\n",
      "epoch: 750, loss = 0.3735557198524475\n",
      "epoch: 775, loss = 0.3580092191696167\n",
      "epoch: 800, loss = 0.36689597368240356\n",
      "epoch: 825, loss = 0.38788914680480957\n",
      "epoch: 850, loss = 0.3555261492729187\n",
      "epoch: 875, loss = 0.3004576563835144\n",
      "epoch: 900, loss = 0.3383738696575165\n",
      "epoch: 925, loss = 0.3398551344871521\n",
      "epoch: 950, loss = 0.35495656728744507\n",
      "epoch: 975, loss = 0.324045330286026\n",
      " --> Accuracy: 0.4791\n",
      "Training model with lr=0.02, weight_decay=0.0005, nepochs=1000, dropout=True\n",
      "epoch: 0, loss = 2.75134015083313\n",
      "epoch: 25, loss = 1.2453219890594482\n",
      "epoch: 50, loss = 0.9346855878829956\n",
      "epoch: 75, loss = 0.7164209485054016\n",
      "epoch: 100, loss = 0.6887943148612976\n",
      "epoch: 125, loss = 0.634414792060852\n",
      "epoch: 150, loss = 0.5968368649482727\n",
      "epoch: 175, loss = 0.5850411653518677\n",
      "epoch: 200, loss = 0.5177093744277954\n",
      "epoch: 225, loss = 0.5207276940345764\n",
      "epoch: 250, loss = 0.46153831481933594\n",
      "epoch: 275, loss = 0.5405317544937134\n",
      "epoch: 300, loss = 0.46120309829711914\n",
      "epoch: 325, loss = 0.4845844805240631\n",
      "epoch: 350, loss = 0.39855697751045227\n",
      "epoch: 375, loss = 0.4538968503475189\n",
      "epoch: 400, loss = 0.4117065370082855\n",
      "epoch: 425, loss = 0.3660629987716675\n",
      "epoch: 450, loss = 0.4132668077945709\n",
      "epoch: 475, loss = 0.38754335045814514\n",
      "epoch: 500, loss = 0.43807095289230347\n",
      "epoch: 525, loss = 0.3494488000869751\n",
      "epoch: 550, loss = 0.3986494541168213\n",
      "epoch: 575, loss = 0.38869708776474\n",
      "epoch: 600, loss = 0.3625231385231018\n",
      "epoch: 625, loss = 0.387147456407547\n",
      "epoch: 650, loss = 0.3321053981781006\n",
      "epoch: 675, loss = 0.3301767408847809\n",
      "epoch: 700, loss = 0.4113597273826599\n",
      "epoch: 725, loss = 0.37409988045692444\n",
      "epoch: 750, loss = 0.3522026240825653\n",
      "epoch: 775, loss = 0.3412321209907532\n",
      "epoch: 800, loss = 0.349642813205719\n",
      "epoch: 825, loss = 0.3259936273097992\n",
      "epoch: 850, loss = 0.3533533215522766\n",
      "epoch: 875, loss = 0.3757854998111725\n",
      "epoch: 900, loss = 0.3514977991580963\n",
      "epoch: 925, loss = 0.31212112307548523\n",
      "epoch: 950, loss = 0.39014047384262085\n",
      "epoch: 975, loss = 0.2772500216960907\n",
      " --> Accuracy: 0.4499\n",
      "Average accuracy over 5 trials = 0.45932335212910747, std = 0.010826536346467809\n"
     ]
    }
   ],
   "source": [
    "nhidden = 32\n",
    "sgd_parms = dict( nepochs = 1000, lr = 0.02, weight_decay = 0.0005, dropout = True )\n",
    "MODEL = GCN\n",
    "ntrails = 5\n",
    "accuracy = []\n",
    "\n",
    "for iT in range(ntrails):\n",
    "    model = MODEL( nfeatures, nhidden, nclasses )\n",
    "    MODEL.train_model( model, graph_data, **sgd_parms )\n",
    "    ( pred, acc ) = MODEL.evaluate_model( model, graph_data )\n",
    "    accuracy.append( acc )\n",
    "\n",
    "acc_data = np.array(accuracy)\n",
    "print( f\"Average accuracy over {ntrails} trials = {acc_data.mean()}, std = {acc_data.std()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# pred_image_data: np.ndarray = pred_data.reshape( [1] + list(raw_spectral_data.shape[1:]) )\n",
    "# pred_image: xa.DataArray = class_map.copy( True, pred_image_data )\n",
    "# class_plot = class_map.hvplot.image( cmap='Category20' )\n",
    "# pred_plot = pred_image.hvplot.image( cmap='Category20' )\n",
    "# pn.Row( class_plot, pred_plot  ).show(\"Indian Pines\")\n",
    "#\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}